{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "E:\\Projects\\skripsi\\alexeyb_darknet_cuda_working_by_vs\\build\\darknet\\x64\nCAP_PROP_FORMAT 0.0\nCAP_PROP_FOURCC 828601953.0\n<class 'int'>\na\nv\nc\n1\navc1\nCAP_PROP_POS_MSEC 0.0\nCAP_PROP_AVI_RATIO 7.8125e-05\nCAP_PROP_FRAME_WIDTH 1280.0\nCAP_PROP_FRAME_HEIGHT 720.0\nCAP_PROP_FPS 25.0\nCAP_PROP_FRAME_COUNT 531.0\nCAP_PROP_MODE 0.0\nCAP_PROP_BRIGHTNESS 0.0\nCAP_PROP_CONTRAST 0.0\nCAP_PROP_SATURATION 0.0\nCAP_PROP_HUE 0.0\nCAP_PROP_GAIN 0.0\nCAP_PROP_EXPOSURE 0.0\nCAP_PROP_CONVERT_RGB 0.0\nCAP_PROP_RECTIFICATION 0.0\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/\"\n",
    "# %ls\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"./Input/video3.mp4\")\n",
    "print(\"CAP_PROP_FORMAT\", cap.get(cv2.CAP_PROP_FORMAT))\n",
    "\n",
    "print(\"CAP_PROP_FOURCC\", cap.get(cv2.CAP_PROP_FOURCC))\n",
    "fourcc = cap.get(cv2.CAP_PROP_FOURCC)\n",
    "fourcc = int(fourcc)\n",
    "fourcc_str = chr(fourcc & 255) + chr((fourcc >> 8) & 255) + chr((fourcc >> 16) & 255) + chr((fourcc >> 24) & 255)\n",
    "print(fourcc_str)\n",
    "\n",
    "print(\"CAP_PROP_POS_MSEC\", cap.get(cv2.CAP_PROP_POS_MSEC))\n",
    "print(\"CAP_PROP_AVI_RATIO\", cap.get(cv2.CAP_PROP_POS_AVI_RATIO))\n",
    "print(\"CAP_PROP_FRAME_WIDTH\", cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "print(\"CAP_PROP_FRAME_HEIGHT\", cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print(\"CAP_PROP_FPS\", cap.get(cv2.CAP_PROP_FPS))\n",
    "print(\"CAP_PROP_FRAME_COUNT\", cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"CAP_PROP_MODE\", cap.get(cv2.CAP_PROP_MODE))\n",
    "print(\"CAP_PROP_BRIGHTNESS\", cap.get(cv2.CAP_PROP_BRIGHTNESS))\n",
    "print(\"CAP_PROP_CONTRAST\", cap.get(cv2.CAP_PROP_CONTRAST))\n",
    "print(\"CAP_PROP_SATURATION\", cap.get(cv2.CAP_PROP_SATURATION))\n",
    "print(\"CAP_PROP_HUE\", cap.get(cv2.CAP_PROP_HUE))\n",
    "print(\"CAP_PROP_GAIN\", cap.get(cv2.CAP_PROP_GAIN))\n",
    "print(\"CAP_PROP_EXPOSURE\", cap.get(cv2.CAP_PROP_EXPOSURE))\n",
    "print(\"CAP_PROP_CONVERT_RGB\", cap.get(cv2.CAP_PROP_CONVERT_RGB))\n",
    "print(\"CAP_PROP_RECTIFICATION\", cap.get(cv2.CAP_PROP_RECTIFICATION))\n",
    "\n",
    "# CAP_PROP_POS_MSEC Current position of the video file in milliseconds or video capture timestamp.\n",
    "# CAP_PROP_POS_FRAMES 0-based index of the frame to be decoded/captured next.\n",
    "# CAP_PROP_POS_AVI_RATIO Relative position of the video file: 0 - start of the film, 1 - end of the film.\n",
    "# CAP_PROP_FRAME_WIDTH Width of the frames in the video stream.\n",
    "# CAP_PROP_FRAME_HEIGHT Height of the frames in the video stream.\n",
    "# CAP_PROP_FPS Frame rate.\n",
    "# CAP_PROP_FOURCC 4-character code of codec.\n",
    "# CAP_PROP_FRAME_COUNT Number of frames in the video file.\n",
    "# CAP_PROP_FORMAT Format of the Mat objects returned by retrieve() .\n",
    "# CAP_PROP_MODE Backend-specific value indicating the current capture mode.\n",
    "# CAP_PROP_BRIGHTNESS Brightness of the image (only for cameras).\n",
    "# CAP_PROP_CONTRAST Contrast of the image (only for cameras).\n",
    "# CAP_PROP_SATURATION Saturation of the image (only for cameras).\n",
    "# CAP_PROP_HUE Hue of the image (only for cameras).\n",
    "# CAP_PROP_GAIN Gain of the image (only for cameras).\n",
    "# CAP_PROP_EXPOSURE Exposure (only for cameras).\n",
    "# CAP_PROP_CONVERT_RGB Boolean flags indicating whether images should be converted to RGB.\n",
    "# CAP_PROP_WHITE_BALANCE Currently not supported\n",
    "# CAP_PROP_RECTIFICATION Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "E:\\Projects\\skripsi\\alexeyb_darknet_cuda_working_by_vs\\build\\darknet\\x64\navc1\n"
     ]
    }
   ],
   "source": [
    "%cd \"/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/\"\n",
    "# %ls\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"./Input/video3.mp4\")\n",
    "fourcc = cap.get(cv2.CAP_PROP_FOURCC)\n",
    "fourcc = int(fourcc)\n",
    "fourcc_str = chr(fourcc & 255) + chr((fourcc >> 8) & 255) + chr((fourcc >> 16) & 255) + chr((fourcc >> 24) & 255)\n",
    "print(fourcc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/\"\n",
    "import darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{1: ['A', 'B', '4'], 5: ('A', 'B', '4'), 0: ['G', 'H'], 3: ['A', 'B']}\n{1: ['A', 'B', '4'], 5: ('A', 'B', '4'), 0: ['G', 'H'], 3: ['A', 'B'], 'ouo': 'red'}\n{1: ['A', 'B', '4'], 5: ('A', 'B', '4'), 0: ['G', 'H'], 3: ['A', 'B'], 'ouo': 'red', 4: '123'}\nA ['B', '4']\nidx:  1\n1 ['A', 'B', '4']\nyes\nidx:  2\n5 ('A', 'B', '4')\nyes\nidx:  3\n0 ['G', 'H']\nno\nidx:  4\n3 ['A', 'B']\nyes\nidx:  5\nouo red\nno\nidx:  6\n4 123\nno\n"
     ]
    }
   ],
   "source": [
    "example_dict = dict()\n",
    "example_dict[1] = ['A', 'B', '4']\n",
    "example_dict[5] = ('A', 'B', '4')\n",
    "example_dict[0] = ['G', 'H']\n",
    "\n",
    "example_dict[3] = ['A', 'B']\n",
    "# updates dict\n",
    "example_dict.update({\"ouo\": \"red\"})\n",
    "# example_dict.update('tes')\n",
    "example_dict[4] = '123'\n",
    "print(example_dict)\n",
    "# id1, p1 = example_dict[1]\n",
    "\n",
    "idx = 1\n",
    "for example in example_dict:\n",
    "    print('idx: ', idx)\n",
    "    print(example, example_dict[example])\n",
    "    if \"B\" in example_dict[example]:\n",
    "        print('yes')\n",
    "    else:\n",
    "        print('no')\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(399, 2)\n"
     ]
    }
   ],
   "source": [
    "another_example_dict = dict()\n",
    "another_example_dict[0] = (399, 2, 393, 0, 406, 6)\n",
    "print(another_example_dict[0][0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 19370 files belonging to 2 classes.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 256, 256, 3), (None,)), types: (tf.float32, tf.int32)>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"E:/Projects/skripsi/alexeyb_darknet_cuda_working_by_vs/build/darknet/x64/Dataset/Crowdhuman/\", labels='inferred', label_mode='int',\n",
    "    class_names=None, color_mode='rgb', batch_size=32, image_size=(256,\n",
    "    256), shuffle=True, seed=None, validation_split=None, subset=None,\n",
    "    interpolation='bilinear', follow_links=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}